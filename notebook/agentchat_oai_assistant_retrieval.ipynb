{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG OpenAI Assistants in AutoGen\n",
    "\n",
    "This notebook shows an example of the [`GPTAssistantAgent`](https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py#L16C43-L16C43) with retrieval augmented generation. `GPTAssistantAgent` is an experimental AutoGen agent class that leverages the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview) for conversational capabilities,  working with\n",
    "`UserProxyAgent` in AutoGen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_new_wrapper: autogen logger is None\n",
      "[runtime logging] log_new_client: autogen logger is None\n",
      "[runtime logging] log_new_agent: autogen logger is None\n",
      "[runtime logging] log_new_agent: autogen logger is None\n",
      "[runtime logging] log_new_agent: autogen logger is None\n",
      "[runtime logging] log_new_agent: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['my-mistral-7b', 'sqlcoder-34b']\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Please explain the code in this file!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_chat_completion: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "\n",
      "https://github.com/dustywillis/jwt-auth/blob/master/middleware.js\n",
      "\n",
      "## Answer (0)\n",
      "\n",
      "This is an implementation of JWT Authentication middleware for NodeJS\n",
      "\n",
      "```\n",
      "const jwt = require('jsonwebtoken');\n",
      "require('dotenv').config();\n",
      "\n",
      "module.exports = function(req, res, next){\n",
      "  const token = req.header('x-auth-token');\n",
      "  if(!token) return res.status(401).send('Access Denied.');\n",
      "  try{\n",
      "    const decoded = jwt.verify(token, process.env.JWT_SECRET);\n",
      "    req.user = decoded;\n",
      "    next();\n",
      "  } catch (error){\n",
      "    res.status(400).send('Invalid token');\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This middleware is applied to any route in your application. It checks for a `x-auth-token` header, which should contain the JWT token that was generated by the user after they logged in.\n",
      "\n",
      "It verifies the token against a secret key defined in the `JWT_SECRET` environment variable, and if it is valid, sets the current user object in the `req` object. This allows you to access the user information from any route that uses this middleware.\n",
      "\n",
      "If the token is invalid or not provided, it returns a 401 status code with an appropriate message.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "terminate\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_chat_completion: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "()\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AssistantAgent' object has no attribute 'delete_assistant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m\n\u001b[1;32m     37\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m UserProxyAgent(\n\u001b[1;32m     38\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_proxy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     code_execution_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m     is_termination_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m msg: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTERMINATE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     41\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m user_proxy\u001b[38;5;241m.\u001b[39minitiate_chat(gpt_assistant, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease explain the code in this file!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mgpt_assistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_assistant\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AssistantAgent' object has no attribute 'delete_assistant'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/simges/autogen/autogen/')\n",
    "import autogen\n",
    "from autogen import UserProxyAgent, config_list_from_json\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import AssistantAgent\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "\n",
    "config_list = config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "}\n",
    "config_list = autogen.config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "assistant_config = {\n",
    "    \"assistant_id\": assistant_id,\n",
    "    \"tools\": [{\"type\": \"retrieval\"}],\n",
    "    \"file_ids\": [\"file-AcnBk5PCwAjJMCVO0zLSbzKP\"],\n",
    "    # add id of an existing file in your openai account\n",
    "    # in this case I added the implementation of conversable_agent.py\n",
    "}\n",
    "\n",
    "gpt_assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"Generate SQL queries with the best quality possible according to given task and return.\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    llm_config=config_list[0]\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "user_proxy.initiate_chat(gpt_assistant, message=\"Please explain the code in this file!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
